"""
LangGraph Insights Graph - AI-powered usage insights generation

This graph takes health report, antipatterns, and statistics data,
then uses an LLM to generate actionable insights and recommendations.
"""

import asyncio
import logging
from typing import Any, Literal, Optional

from typing_extensions import TypedDict
from pydantic import BaseModel, Field
from langgraph.graph import StateGraph, START, END

from app.agents.llm_factory import LLMFactory, LLMConfig, LLMProvider

logger = logging.getLogger(__name__)

from app.services.data_reader import DataReader
from app.services.health_scorer import HealthScorer
from app.services.antipattern_engine import AntipatternEngine
from app.services.statistics_service import StatisticsService


# Pydantic models for structured output
class Insight(BaseModel):
    """A single insight generated by the AI"""
    type: Literal["warning", "tip", "achievement"] = Field(
        description="Type of insight"
    )
    title: str = Field(
        description="Short title for the insight (5-10 words)"
    )
    description: str = Field(
        description="Detailed description of the insight (1-2 sentences)"
    )
    impact: Literal["high", "medium", "low"] = Field(
        description="Impact level of addressing this insight"
    )
    actionable: Optional[str] = Field(
        default=None,
        description="Specific action user can take"
    )


class InsightsOutput(BaseModel):
    """Structured output from the LLM"""
    insights: list[Insight] = Field(
        description="List of insights generated"
    )
    summary: str = Field(
        description="One-paragraph summary of overall usage patterns and recommendations"
    )


# LangGraph State
class InsightsState(TypedDict):
    """State for the insights graph"""
    # Input parameters
    days: int
    project: Optional[str]
    llm_provider: str
    llm_model: Optional[str]

    # Loaded data
    health_report: Optional[dict[str, Any]]
    antipatterns: Optional[list[dict[str, Any]]]
    statistics: Optional[dict[str, Any]]

    # Output
    insights: list[dict[str, Any]]
    summary: str
    error: Optional[str]


# Node functions
async def load_data(state: InsightsState) -> InsightsState:
    """Load all required data for analysis"""
    try:
        reader = DataReader()
        health_scorer = HealthScorer()
        antipattern_engine = AntipatternEngine()
        stats_service = StatisticsService()

        days = state["days"]
        project = state.get("project")

        # Load prompts and sessions
        prompts = await reader.get_prompts(project=project, days=days)
        sessions = await reader.get_sessions(project=project, days=days)

        # Calculate health report
        antipatterns = antipattern_engine.detect_all(prompts)
        health_report = health_scorer.calculate_health_report(prompts, antipatterns, days)

        # Calculate statistics
        statistics = stats_service.calculate_overview(prompts, sessions, days)

        return {
            **state,
            "health_report": health_report.model_dump(),
            "antipatterns": [ap.model_dump() for ap in antipatterns],
            "statistics": statistics.model_dump(),
            "error": None,
        }
    except Exception as e:
        logger.error("Failed to load data for analysis", exc_info=True, extra={
            "days": state.get("days"),
            "project": state.get("project"),
            "error_type": type(e).__name__,
        })
        return {
            **state,
            "health_report": None,
            "antipatterns": None,
            "statistics": None,
            "error": f"Failed to load data: {str(e)}",
        }


async def generate_insights(state: InsightsState) -> InsightsState:
    """Generate insights using LLM"""
    if state.get("error"):
        return state

    try:
        # Validate and create LLM config
        provider_name = state["llm_provider"]
        try:
            provider = LLMProvider(provider_name)
        except ValueError:
            valid_providers = ", ".join(p.value for p in LLMProvider)
            return {
                **state,
                "insights": [],
                "summary": "",
                "error": f"Invalid LLM provider: {provider_name}. Must be one of: {valid_providers}",
            }

        config = LLMConfig(
            provider=provider,
            model=state.get("llm_model"),
            temperature=0.3,  # Lower temperature for more consistent output
        )

        # Create LLM with structured output
        llm = LLMFactory.create(config)
        structured_llm = llm.with_structured_output(InsightsOutput)

        # Build prompt
        prompt = _build_analysis_prompt(
            health_report=state["health_report"],
            antipatterns=state["antipatterns"],
            statistics=state["statistics"],
            days=state["days"],
        )

        # Invoke LLM
        result: InsightsOutput = await structured_llm.ainvoke(prompt)

        return {
            **state,
            "insights": [insight.model_dump() for insight in result.insights],
            "summary": result.summary,
            "error": None,
        }
    except Exception as e:
        logger.error("Failed to generate insights", exc_info=True, extra={
            "llm_provider": state.get("llm_provider"),
            "llm_model": state.get("llm_model"),
            "error_type": type(e).__name__,
        })
        return {
            **state,
            "insights": [],
            "summary": "",
            "error": f"Failed to generate insights: {str(e)}",
        }


async def deep_analysis(state: InsightsState) -> InsightsState:
    """Perform deep analysis for low health scores"""
    if state.get("error"):
        return state

    health_report = state.get("health_report", {})
    overall_score = health_report.get("overall_score", 100)

    # Only run deep analysis if score is low
    if overall_score >= 60:
        return state

    try:
        # Create LLM config
        provider = LLMProvider(state["llm_provider"])
        config = LLMConfig(
            provider=provider,
            model=state.get("llm_model"),
            temperature=0.4,
        )

        llm = LLMFactory.create(config)

        # Build deep analysis prompt
        prompt = _build_deep_analysis_prompt(
            health_report=state["health_report"],
            antipatterns=state["antipatterns"],
            statistics=state["statistics"],
        )

        # Get additional analysis
        response = await llm.ainvoke(prompt)

        # Add to summary
        current_summary = state.get("summary", "")
        deep_insights = response.content if hasattr(response, 'content') else str(response)

        return {
            **state,
            "summary": f"{current_summary}\n\n**Deep Analysis:**\n{deep_insights}",
        }
    except Exception as e:
        # Don't fail the whole graph, just skip deep analysis
        return state


def router(state: InsightsState) -> str:
    """Route to deep analysis if health score is low"""
    if state.get("error"):
        return "end"

    health_report = state.get("health_report", {})
    overall_score = health_report.get("overall_score", 100)

    if overall_score < 60:
        return "deep_analysis"
    return "end"


def _sanitize_string(value: Any, max_length: int = 100) -> str:
    """Sanitize string input to prevent prompt injection"""
    if value is None:
        return ""
    s = str(value)
    # Remove potential prompt injection patterns
    s = s.replace("```", "")
    s = s.replace("##", "")
    s = s.replace("Ignore", "ignore")
    s = s.replace("IGNORE", "ignore")
    return s[:max_length]


def _sanitize_number(value: Any, min_val: int = 0, max_val: int = 100) -> int:
    """Sanitize numeric input"""
    try:
        num = int(value)
        return max(min_val, min(max_val, num))
    except (ValueError, TypeError):
        return min_val


def _build_analysis_prompt(
    health_report: dict,
    antipatterns: list,
    statistics: dict,
    days: int,
) -> str:
    """Build the main analysis prompt with input sanitization"""
    # Summarize antipatterns by type (sanitized)
    antipattern_summary = {}
    for ap in antipatterns[:50]:  # Limit to 50 entries
        ap_type = _sanitize_string(ap.get("type", "unknown"), 30)
        antipattern_summary[ap_type] = antipattern_summary.get(ap_type, 0) + 1

    return f"""You are an expert AI assistant usage analyst. Analyze the following Claude Code usage data and generate actionable insights.

## Data Period: Last {days} days

## Health Report
- Overall Score: {health_report.get('overall_score', 'N/A')}/100 (Grade: {health_report.get('grade', 'N/A')})
- Total Prompts Analyzed: {health_report.get('total_prompts_analyzed', 0)}
- Dimensions:
{_format_dimensions(health_report.get('dimensions', []))}

## Anti-patterns Detected
{_format_antipatterns(antipattern_summary)}

## Usage Statistics
- Total Sessions: {statistics.get('total_sessions', 0)}
- Total Prompts: {statistics.get('total_prompts', 0)}
- Avg Prompts per Session: {statistics.get('avg_prompts_per_session', 0):.1f}
- Extended Thinking Usage: {statistics.get('thinking_usage_rate', 0):.1%}

## Existing Suggestions from Health Report
{_format_suggestions(health_report.get('improvement_suggestions', []))}

Based on this data, generate 3-5 insights that are:
1. Specific and actionable
2. Prioritized by impact
3. Mix of warnings (issues to fix), tips (improvements), and achievements (positive patterns)

Focus on the most impactful improvements the user can make to their Claude Code usage."""


def _build_deep_analysis_prompt(
    health_report: dict,
    antipatterns: list,
    statistics: dict,
) -> str:
    """Build prompt for deep analysis of low scores"""
    return f"""The user has a low Claude Code usage health score of {health_report.get('overall_score', 0)}/100.

Analyze the root causes and provide a detailed action plan:

Anti-patterns detected: {len(antipatterns)}
Dimensions with lowest scores: {_get_lowest_dimensions(health_report.get('dimensions', []))}

Provide 3-5 specific, concrete steps the user should take to improve their score.
Focus on the most impactful changes first. Be specific about what good vs bad looks like."""


def _format_dimensions(dimensions: list) -> str:
    """Format dimension scores for the prompt with sanitization"""
    if not dimensions:
        return "  (No dimension data available)"

    lines = []
    for dim in dimensions[:10]:  # Limit to 10 dimensions
        name = _sanitize_string(dim.get("name", "unknown"), 30)
        score = _sanitize_number(dim.get("score", 0), 0, 100)
        issues = dim.get("issues", [])
        lines.append(f"  - {name}: {score}/100")
        if issues:
            for issue in issues[:2]:  # Limit to 2 issues per dimension
                sanitized_issue = _sanitize_string(issue, 100)
                lines.append(f"    * {sanitized_issue}")
    return "\n".join(lines)


def _format_antipatterns(summary: dict) -> str:
    """Format antipattern summary for the prompt"""
    if not summary:
        return "  No anti-patterns detected!"

    lines = []
    for ap_type, count in sorted(summary.items(), key=lambda x: -x[1]):
        lines.append(f"  - {ap_type}: {count} occurrences")
    return "\n".join(lines)


def _format_suggestions(suggestions: list) -> str:
    """Format existing suggestions with sanitization"""
    if not suggestions:
        return "  (None)"
    sanitized = [_sanitize_string(s, 150) for s in suggestions[:10]]
    return "\n".join(f"  - {s}" for s in sanitized)


def _get_lowest_dimensions(dimensions: list) -> str:
    """Get the lowest scoring dimensions with sanitization"""
    if not dimensions:
        return "N/A"

    sorted_dims = sorted(dimensions, key=lambda d: d.get("score", 100))
    lowest = sorted_dims[:2]
    return ", ".join(
        f"{_sanitize_string(d.get('name', 'unknown'), 30)} ({_sanitize_number(d.get('score', 0), 0, 100)})"
        for d in lowest
    )


def create_insights_graph():
    """Create and compile the insights graph"""
    builder = StateGraph(InsightsState)

    # Add nodes
    builder.add_node("load_data", load_data)
    builder.add_node("generate_insights", generate_insights)
    builder.add_node("deep_analysis", deep_analysis)

    # Add edges
    builder.add_edge(START, "load_data")
    builder.add_edge("load_data", "generate_insights")
    builder.add_conditional_edges(
        "generate_insights",
        router,
        {
            "deep_analysis": "deep_analysis",
            "end": END,
        }
    )
    builder.add_edge("deep_analysis", END)

    return builder.compile()


# Thread-safe singleton graph instance
_insights_graph = None
_graph_lock = asyncio.Lock()


async def get_insights_graph():
    """Get or create the insights graph instance (async-safe)"""
    global _insights_graph
    async with _graph_lock:
        if _insights_graph is None:
            _insights_graph = create_insights_graph()
    return _insights_graph


async def run_insights_analysis(
    days: int = 30,
    project: Optional[str] = None,
    llm_provider: str = "openai",
    llm_model: Optional[str] = None,
) -> dict:
    """
    Run the insights analysis graph.

    Args:
        days: Number of days to analyze
        project: Optional project filter
        llm_provider: LLM provider to use (openai, anthropic, deepseek, ollama)
        llm_model: Optional specific model to use

    Returns:
        Dictionary with insights, summary, and any errors
    """
    graph = await get_insights_graph()

    initial_state: InsightsState = {
        "days": days,
        "project": project,
        "llm_provider": llm_provider,
        "llm_model": llm_model,
        "health_report": None,
        "antipatterns": None,
        "statistics": None,
        "insights": [],
        "summary": "",
        "error": None,
    }

    result = await graph.ainvoke(initial_state)

    return {
        "insights": result.get("insights", []),
        "summary": result.get("summary", ""),
        "health_report": result.get("health_report"),
        "statistics": result.get("statistics"),
        "error": result.get("error"),
    }
